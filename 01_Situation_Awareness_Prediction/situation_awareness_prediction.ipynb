{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH1iOoklJIaw"
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOd4Bo9_JJ6x",
    "outputId": "1df024fe-e7f4-4d67-c0ad-885a463af218"
   },
   "outputs": [],
   "source": [
    "# HERE WE IMPORT ALL THE NECESSARIES LIBRARIES FOR OUR PROJECT\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g-fCPvYJotr"
   },
   "source": [
    "# DATA IMPORT AND PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQHOBOXtfmq5"
   },
   "source": [
    "## Data Import Process\n",
    "The data was provided in a CSV file named SAdata_allMeasures.csv.  The Pandas library and Python were used to import the file into the Google Colab environment. In the following Steps.\n",
    "\n",
    "1.   **Upload the Data File:** The Google Colab environment's file upload function was used to upload the CSV file.\n",
    "\n",
    "2. **Load the Data:** The read_csv function was used to load the data into a Pandas DataFrame.\n",
    "\n",
    "3. **Initial Data Exploration:** The initial few rows, shape, were printed to confirm that the dataset was loaded successfully.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvXmg1NMJ62W"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/content/drive/MyDrive/SAdata_allMeasures.csv'\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6292RmhWwKj"
   },
   "source": [
    "**DESCRIPTION OF THE DATASET**\n",
    "\n",
    "There are 29 features (columns) and 1054 (rows) in the dataset, which includes both categorical and numerical variables. The dependent variable for prediction is represented by the target variable, Y.\n",
    "\n",
    "**Overview of Features**\n",
    "Numerical features are quantifiable values that include pupil changes, age, and time-based measurements.\n",
    "\n",
    "*Numerical*: age, yearDriving, temp_length, temp_decisiontime, temp_correct_decision, pupilChange, pupilMean, pupilStd.\n",
    "\n",
    "Categorical features are statistics that are based on groups, such as gender or choices.\n",
    "\n",
    "Categorical: gender, temp_decision_made, CarPlacedLeft, CarPlacedRight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biFkNz3hRFgh"
   },
   "source": [
    "In the  Original Shape before Preprocessing our data is\n",
    "**Total rows: 1054**,\n",
    "**Total columns: 29**\n",
    "These 29 columns include both numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xucbeoi1KfkU",
    "outputId": "9a9a1fc5-439a-43ce-d1a8-8adf8a593249"
   },
   "outputs": [],
   "source": [
    "#Print the shape of data\n",
    "print(\"Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "PePDa25aKUzK",
    "outputId": "8667bf8f-7cf8-46ff-aa52-7c228c0d6edd"
   },
   "outputs": [],
   "source": [
    "#Priting the first 5 elements of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGSOVZWmKqQo"
   },
   "source": [
    "FINDING MISSING VALUES:\n",
    "The dataset is complete, with no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GqJhd_UKsVX",
    "outputId": "dd905227-f627-4f26-e72e-23c3257e6ca9"
   },
   "outputs": [],
   "source": [
    "print(\"Missing Values:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bzohh5WWLTYk"
   },
   "source": [
    "#DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9UHbQgN2GEo"
   },
   "source": [
    "To prepare the data for machine learning algorithms, we used preprocessing techniques in this project. We specifically concentrated on employing one-hot encoding to handle categorical data while maintaining the integrity of numerical variables. The actions done during preprocessing are listed below:\n",
    "\n",
    "**Step 1: Define Features and Target**\n",
    "We started by defining the training features and the target variable (Y). The features are the input variables, and the target variable is the result we are attempting to predict.\n",
    "\n",
    "**Step 2: Split the Data**\n",
    "The dataset was divided into two parts: training and testing sets. The testing set was utilized to assess the model's performance, and the training set was utilized to train the model.\n",
    "\n",
    "**Step 3: Preprocessing Pipeline**\n",
    "Next, we created a preprocessing pipeline. The OneHotEncoder was used to handle categorical features by converting them into numerical representations. For the numerical features, no transformation was applied.\n",
    "\n",
    "**Step 4: Apply Preprocessing and print Output**\n",
    "After defining the pipeline, we applied it to both the training and testing datasets.\n",
    "To make sure the preparation procedures were followed correctly and the data was prepared for training, we lastly printed the shapes of the converted datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ngcy6IrbRuwc"
   },
   "source": [
    "**Splitting the Data**\n",
    "Train-test split divides the data into :\n",
    "Training data:** 843 rows (80%)**\n",
    "Testing data: **211 rows (20%)**\n",
    "\n",
    "**After Preprocessing**\n",
    "due to OneHotEncoding of categorical features  increase from **29 to 37** features, because it  creates additional binary columns for each unique category\n",
    "\n",
    "**Justification for Preprocessing Choices**\n",
    "Categorical Variables: One-hot encoding was chosen for categorical variables because it is effective for handling categories—it was selected for categorical variables.\n",
    "\n",
    "Numerical Variables: Numerical features were left unchanged in this case, as they do not require further transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7wDS9XvLWKs",
    "outputId": "2516c379-b331-410b-f5ab-847339426d83"
   },
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_column = 'Y'  # The target variable\n",
    "categorical_features = ['gender', 'temp_decision_made', 'CarPlacedLeft', 'CarPlacedRight']\n",
    "numerical_features = [col for col in data.columns if col not in categorical_features + [target_column]]\n",
    "\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# ColumnTransformer applies OneHotEncoder to the categorical columns and leaves the numerical features untouched\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features) # Apply OneHotEncoder to categorical columns\n",
    "    ], remainder='passthrough')  # Leave numerical features as they are\n",
    "\n",
    "# Create a pipeline that applies the preprocessor\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and Transform the training and test data\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "#Print the Shape of the transformed datasets\n",
    "print(\"Processed Training Shape:\", X_train_processed.shape)\n",
    "print(\"Processed Testing Shape:\", X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JogPzxwsL5FD"
   },
   "source": [
    "VISUALIZE CORRELATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgTDygmFi2TB"
   },
   "source": [
    "Using the correlation heatmap that has been printed we can find some strong positive correlation and no negative correlations.\n",
    "\n",
    "I chose not to eliminate any features despite the fact that some of them have been correlated because each one reflects distinct characteristics in the data. If a feature is removed, important information that could enhance model performance could be lost. In contrast, XGBoost and LightGBM are naturally able to handle correlated features and are robust to multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zqUseGdOL9OM",
    "outputId": "e4137160-3deb-47c4-ccbd-d9377f6fe5b0"
   },
   "outputs": [],
   "source": [
    "# Only select numerical features\n",
    "numerical_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features (absolute value > 0.8)\n",
    "high_correlation = correlation_matrix[(correlation_matrix > 0.8) & (correlation_matrix < 1.0)]\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(high_correlation.dropna(how='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AMBzUHF6LCJ"
   },
   "source": [
    " # Implement XGBoost with Both RMSE, MAE, Training Time and Running Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOPdNcT29E95"
   },
   "source": [
    "The first machine learning model we will use in this project is called XGBoost (Extreme Gradient Boosting), which is a potent gradient boosting-based machine learning technique. It excels in many kinds of classification and regression problems and is renowned for its scalability, flexibility, and efficiency.\n",
    "\n",
    "Model Architecture\n",
    "XGBoost works by building multiple decision trees in a sequential manner. Each new tree corrects the errors made by the previous ones, resulting in a strong ensemble model. The architecture includes:\n",
    "\n",
    "**Objective**: We are using the reg:squarederror objective function for regression tasks.\n",
    "\n",
    "Learning Rate: The learning rate is set to 0.1, which controls how much each tree contributes to the final prediction.\n",
    "\n",
    "**Maximum Depth:** The depth of each tree is limited to 3 to prevent overfitting and ensure good generalization.\n",
    "\n",
    "**Number of Estimators:** We trained the model for 100 trees (n_estimators = 100).\n",
    "\n",
    "**Regularization Parameters:** We applied L2 regularization (reg_lambda) to prevent overfitting.\n",
    "\n",
    "**Hyperparameters**\n",
    "Here is the configuration used for training the XGBoost model the best values were found using GrdSearch:\n",
    "\n",
    "objective: Defines the type of problem (regression).\n",
    "colsample_bytree: Fraction of features used per tree (helps with generalization).\n",
    "subsample: Fraction of samples used per tree.\n",
    "learning_rate: Controls the step size at each iteration.\n",
    "max_depth: Depth of each individual tree.\n",
    "n_estimators: Number of trees to build.\n",
    "\n",
    "**Training Model**\n",
    "We trained the model using The train() method in XGBoost is used to train the model, passing the evaluation set and training dataset. To make sure the model is convergent, the training method involves tracking the performance measures (RMSE and MAE) at each iteration.\n",
    "\n",
    "**Model Evaluation**\n",
    "We evaluate the model using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).\n",
    "\n",
    "Visualizing the Results\n",
    "To monitor the model’s convergence, we visualize the RMSE and MAE over the training iterations.We also display the Training and Running Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPfKMVwCDHar"
   },
   "source": [
    "**Evaluation of Model Performance**\n",
    "Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) were used to assess the performance of the XGBoost model after it was trained on the dataset. Plotting the training convergence above demonstrates that both the RMSE and MAE drastically dropped early in the training process, stabilizing about 50–60 cycles. This shows that learning and optimizing the model's parameters was successful.\n",
    "\n",
    "**The following are the test set's final results:**\n",
    "RMSE: 0.1052, indicating that the model's predictions, on average, deviate from actual values by about 0.1052 units. This is a good indicator of predictive accuracy.\n",
    "MAE: 0.0828, demonstrating that the average absolute error between predicted and actual values is about 0.0828 units.\n",
    "The model trained in 1.96 seconds, showcasing the efficiency of XGBoost in handling the given dataset. Moreover, the prediction time for new data was just 0.0017 seconds, reflecting the model's suitability for fast inference tasks.\n",
    "Low error metrics and quick training and prediction timeframes indicate that the model is efficient and successful for the given regression job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "bjoeeDpE6byw",
    "outputId": "3431bcd4-08f0-40e4-c889-be91cb0693f7"
   },
   "outputs": [],
   "source": [
    "# Prepare the DMatrix for training and test set\n",
    "dtrain = xgb.DMatrix(X_train_processed, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_processed, label=y_test)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_lambda': 1,\n",
    "    'subsample': 1.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 100,\n",
    "    'gamma': 0,\n",
    "    'eval_metric': ['rmse', 'mae']  # Track both RMSE and MAE\n",
    "}\n",
    "\n",
    "# Create a dictionary to log metrics\n",
    "evals_result_xgb = {}\n",
    "\n",
    "# Track training time\n",
    "start_train_time = time.time()\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(\n",
    "    params=xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100,  # Number of iterations\n",
    "    evals=[(dtrain, 'train'), (dtest, 'valid')],  # Evaluate on both train and test\n",
    "    evals_result=evals_result_xgb,\n",
    "    verbose_eval=False  # Set to True to see training progress\n",
    ")\n",
    "\n",
    "end_train_time = time.time()\n",
    "training_time_xgb = end_train_time - start_train_time\n",
    "\n",
    "# Extract RMSE and MAE for each iteration\n",
    "validation_rmse_xgb = evals_result_xgb['valid']['rmse']\n",
    "validation_mae_xgb = evals_result_xgb['valid']['mae']\n",
    "\n",
    "# Predict on the test set and compute RMSE and MAE\n",
    "start_run_time = time.time()\n",
    "y_pred_xgb = xgb_model.predict(dtest)\n",
    "end_run_time = time.time()\n",
    "running_time_xgb = end_run_time - start_run_time\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Print final results\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"Final RMSE on Test Set: {rmse_xgb:.4f}\")\n",
    "print(f\"Final MAE on Test Set: {mae_xgb:.4f}\")\n",
    "print(f\"Training Time: {training_time_xgb:.2f} seconds\")\n",
    "print(f\"Running Time: {running_time_xgb:.4f} seconds\")\n",
    "\n",
    "# Plot Validation RMSE and MAE over iterations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(validation_rmse_xgb, label='Validation RMSE', color='blue')\n",
    "plt.plot(validation_mae_xgb, label='Validation MAE', color='green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('XGBoost Training Convergence (RMSE and MAE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XxIEG0OGOvS"
   },
   "source": [
    "**Training and Validation Loss**\n",
    "\n",
    "The plot above shows the RMSE loss for both the training set (blue line) and the validation set (orange line) over 100 iterations. The model's performance improves during the initial iterations, with the training loss decreasing significantly. This indicates that the model is successfully learning from the training data.\n",
    "\n",
    "However, after around 30-40 iterations, the validation loss stagnates, indicating that the model has reached a point where it no longer improves on the unseen validation data. The slight gap between the training loss and validation loss is typical, where the model tends to perform better on the training set compared to the validation set.\n",
    "\n",
    "This pattern suggests that the model has effectively learned most of the patterns in the data, and further training may lead to overfitting.\n",
    "\n",
    "In order to avoid overfitting and guarantee that the model performs well when applied to new data, early stopping could be used in practice to end the training process as soon as the validation loss stops getting better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "xUXmE5cXBTzJ",
    "outputId": "5baa6bc8-e200-421b-c117-2dec4d6ff75c"
   },
   "outputs": [],
   "source": [
    "# Extract Metrics\n",
    "train_loss = evals_result_xgb['train']['rmse']\n",
    "valid_loss = evals_result_xgb['valid']['rmse']\n",
    "iterations = np.arange(len(train_loss)) + 1\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, train_loss, label='Training Loss (RMSE)', color='blue')\n",
    "plt.plot(iterations, valid_loss, label='Validation Loss (RMSE)', color='orange')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('XGBoost: Training and Validation Loss vs Iterations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UQsOsWTHbQU"
   },
   "source": [
    "# TUNING XGBOOST : GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvIGjq5tHNR7",
    "outputId": "1606258d-8a5a-4d1f-9d35-95cb960099ee"
   },
   "outputs": [],
   "source": [
    "#Tuning XGBOOST\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 6, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_lambda': [0, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# GridSearchCV for XGBoost\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train_processed, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "print(\"Best RMSE (negative MSE):\", (-grid_search_xgb.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "728gljx-H-RH"
   },
   "source": [
    "#  Relationship Between RMSE and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKDF1-nQH_KH",
    "outputId": "dbe91f3f-d765-497f-8c1e-41ba09dced41"
   },
   "outputs": [],
   "source": [
    "# Convert the GridSearchCV results into a DataFrame\n",
    "results = pd.DataFrame(grid_search_xgb.cv_results_)\n",
    "\n",
    "# Select relevant columns\n",
    "results_summary = results[['param_learning_rate', 'param_max_depth',\n",
    "                           'param_n_estimators', 'param_subsample',\n",
    "                           'param_colsample_bytree', 'param_gamma',\n",
    "                           'param_reg_lambda', 'mean_test_score']]\n",
    "\n",
    "# Add RMSE column (convert negative MSE back to RMSE)\n",
    "results_summary['RMSE'] = (-results_summary['mean_test_score'])**0.5\n",
    "\n",
    "# Sort values for better visualization\n",
    "results_summary = results_summary.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "# Display the table\n",
    "print(results_summary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzDv3-X5liwM"
   },
   "source": [
    "1. Plot RMSE vs learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifjkFtU8o7Cx"
   },
   "source": [
    "The ideal learning rate for model training is approximately 0.025. By doing this, we may minimize error, avoid overfitting or instability during training, and make sure the model converges at the fastest possible rate.\n",
    "\n",
    "Interpretation\n",
    "\n",
    "The plot below shows the relationship between the learning rate and the mean RMSE (Root Mean Squared Error). Several important conclusions can be made by examining the plot:\n",
    "\n",
    "Initial Sharp Decline: The RMSE begins to drop sharply, from about 0.121 to 0.117, at a learning rate of about 0.025. This implies that this learning rate leads to a significant improvement in the model's performance, suggesting that the rate promotes efficient learning and quicker convergence.\n",
    "\n",
    "Steady RMSE Performance (0.05 to 0.125): The RMSE stabilizes as the learning rate rises from 0.05 to 0.125. The model's performance does not change significantly within this range, indicating that current learning rates enable the model to converge without producing appreciable errors.\n",
    "\n",
    "Increase in RMSE with Higher Learning Rates: The RMSE starts to increase once more when the learning rate surpasses 0.125, reaching values of approximately 0.118 to 0.121. This suggests that the model finds it difficult to converge efficiently at greater learning rates, which could cause it to overshoot ideal values and perform worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "oubORqVGlje2",
    "outputId": "cbea6025-4380-4e57-fa7c-9843b3311564"
   },
   "outputs": [],
   "source": [
    "# Plot RMSE vs learning_rate\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=results_summary, x='param_learning_rate', y='RMSE', marker='o')\n",
    "plt.title('Relationship Between RMSE and Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Mean RMSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKTDp56IrKnb"
   },
   "source": [
    "2. Plot RMSE vs max_depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlfoNcR10tct"
   },
   "source": [
    "The graph shows how the mean RMSE (Root Mean Squared Error) and the model's maximum depth—a parameter that controls tree depth—relate to one another. It is possible to find the ideal balance between underfitting and overfitting by examining how RMSE varies with maximum depth.\n",
    "\n",
    "Implications for Model Tuning:\n",
    "\n",
    "According to the findings, the optimal performance with the lowest RMSE is obtained when max depth = 3. Without overfitting the data, this depth enables the model to generalize effectively.\n",
    "Because they result in increased RMSE, which indicates overfitting and decreased generalization ability, higher max depths (5 to 7) should be avoided.\n",
    "\n",
    "Interpretation\n",
    "\n",
    "Increasing RMSE with Max Depth: The plot indicates a consistent rise in RMSE from 3 to 7 as the maximum depth increases. This pattern suggests that permitting deeper trees results in a minor increase in error rather than better model performance.\n",
    "\n",
    "Max Depth = 3 has the lowest RMSE: The RMSE is at its lowest (~0.1176) at max depth = 3. This shows that the model works best with a shallow tree, most likely because it finds a balance between overfitting and underfitting.\n",
    "\n",
    "Performance Decline Beyond Depth = 3: Although the difference is slight, RMSE keeps increasing as max depth rises from 5 to 7. This trend suggests that the model may be overfitting due to deeper trees, catching noise in the data instead of general patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "PF9kMTWvrMAK",
    "outputId": "d48f50e5-dfcc-449f-f3ee-c28d4f387f33"
   },
   "outputs": [],
   "source": [
    "# Plot RMSE vs max_depth\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(data=results_summary, x='param_max_depth', y='RMSE', marker='o')\n",
    "plt.title('Relationship Between RMSE and Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Mean RMSE')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_3fbWRitHuA"
   },
   "source": [
    " Plot RMSE vs. n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "TZRw7PQotJ2C",
    "outputId": "da3a0255-a02e-4089-ac7d-603b4bb3329f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=results_summary['param_n_estimators'].astype(int),\n",
    "             y=results_summary['RMSE'])\n",
    "plt.title('RMSE vs n_estimators')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtIwaQOUtVWM"
   },
   "source": [
    "Plot RMSE vs colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQorXX174a6-"
   },
   "source": [
    "Colsample_bytree's Effect on Model Performance\n",
    "The graph looks at the correlation between the Root Mean Squared Error (RMSE) and colsample_bytree, or the percentage of features utilized for training each tree.\n",
    "\n",
    "Implications for Model Tuning:\n",
    "\n",
    "Setting colsample_bytree = 0.8 yields slightly better performance with the lowest RMSE, making it a reasonable choice for training.\n",
    "Since the RMSE remains stable for values beyond 0.8, using higher values (e.g., 0.9 or 1.0) does not degrade performance but does not improve it either.\n",
    "Lower values (<0.8) can lead to slight increases in RMSE, potentially due to insufficient feature usage.\n",
    "\n",
    "\n",
    "Important Points to Note:\n",
    "\n",
    "Stability of RMSE Across colsample_bytree: As colsample_bytree rises from 0.7 to 1.0, the RMSE values are largely constant. The RMSE decreases very slightly up to 0.8, after which there is very little change.\n",
    "\n",
    "At colsample_bytree = 0.8, the lowest RMSE: The RMSE reaches its lowest value (~0.118) at 0.8, indicating that the optimal model performance is achieved when 80% of the available features are used per tree.\n",
    "\n",
    "Narrow Variation in RMSE: The model is intolerant to slight variations in the colsample_bytree parameter, as evidenced by the shaded confidence interval, which shows little variability over the range of colsample_bytree values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "OraGP8nStWIf",
    "outputId": "e2a5b292-1798-4d31-df74-afb95abfe867"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=results_summary['param_colsample_bytree'].astype(float),\n",
    "             y=results_summary['RMSE'])\n",
    "plt.title('RMSE vs colsample_bytree')\n",
    "plt.xlabel('colsample_bytree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtdQqW1vtjfe"
   },
   "source": [
    " Plot RMSE vs subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CW4mJ19A5tJN"
   },
   "source": [
    "Subsample's Effect on Model Performance\n",
    "The graph shows how the Root Mean Squared Error (RMSE) and the subsample parameter—the percentage of training data utilized for each boosting iteration—relate to one another. It is essential to modify this value in order to balance overfitting and performance.\n",
    "\n",
    "Implications Model tuning: Subsample = 0.9 is the ideal setting since it offers the lowest RMSE with the least amount of variability.\n",
    "A greater RMSE and more model instability, perhaps from overfitting, result from setting the subsample to 1.0.\n",
    "While using smaller subsample values (such as 0.7–0.8) still yields competitive RMSE, training data may be underutilized.\n",
    "\n",
    "Important Points to Note:\n",
    "From 0.7 to 0.9, the RMSE continuously declines as the subsample grows, reaching its lowest RMSE at 0.9 (~0.1178).\n",
    "\n",
    "When the subsample reaches 1.0, the RMSE rises substantially over 0.9, suggesting a possible loss of regularization.\n",
    "\n",
    "0.9 is the lowest RMSE at the subsample. 90% of the training data should be used for each boosting iteration for the model to function at its best because this balances regularization and variance reduction.\n",
    "\n",
    "High Variability at subsample = 1.0: Reflecting greater variability and possible overfitting when using the complete dataset, the shaded confidence interval greatly increases at subsample = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "FDtw7hhBtkjX",
    "outputId": "316b80fe-9a8c-46d2-f5c4-740c0089cd5f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=results_summary['param_subsample'].astype(float),\n",
    "             y=results_summary['RMSE'])\n",
    "plt.title('RMSE vs subsample')\n",
    "plt.xlabel('subsample')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKC-ofYDtwLm"
   },
   "source": [
    "Heatmap of RMSE and the Hyperamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "ARhVJ3betrj6",
    "outputId": "c4c15372-6547-41ec-aea4-bccba462ecc6"
   },
   "outputs": [],
   "source": [
    "# Create pivot tables for each pair of hyperparameters\n",
    "pivot_1 = results_summary.pivot_table(values='RMSE',\n",
    "                                      index='param_max_depth',\n",
    "                                      columns='param_n_estimators')\n",
    "pivot_2 = results_summary.pivot_table(values='RMSE',\n",
    "                                      index='param_learning_rate',\n",
    "                                      columns='param_colsample_bytree')\n",
    "pivot_3 = results_summary.pivot_table(values='RMSE',\n",
    "                                      index='param_subsample',\n",
    "                                      columns='param_gamma')\n",
    "\n",
    "# Plot multiple heatmaps in subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Heatmap 1: max_depth vs n_estimators\n",
    "sns.heatmap(pivot_1, annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=axes[0])\n",
    "axes[0].set_title(\"max_depth vs n_estimators\")\n",
    "axes[0].set_xlabel(\"n_estimators\")\n",
    "axes[0].set_ylabel(\"max_depth\")\n",
    "\n",
    "# Heatmap 2: learning_rate vs colsample_bytree\n",
    "sns.heatmap(pivot_2, annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=axes[1])\n",
    "axes[1].set_title(\"learning_rate vs colsample_bytree\")\n",
    "axes[1].set_xlabel(\"colsample_bytree\")\n",
    "axes[1].set_ylabel(\"learning_rate\")\n",
    "\n",
    "# Heatmap 3: subsample vs gamma\n",
    "sns.heatmap(pivot_3, annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=axes[2])\n",
    "axes[2].set_title(\"subsample vs gamma\")\n",
    "axes[2].set_xlabel(\"gamma\")\n",
    "axes[2].set_ylabel(\"subsample\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6ZIeZwWvEDg"
   },
   "source": [
    "# XGBOOST CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVEzU4YJ-02r"
   },
   "source": [
    "Conclusion:\n",
    "\n",
    "\"The 10-fold cross-validation results indicate that the XGBoost Regressor achieved a mean RMSE of 0.1114 and a mean MAE of 0.0869, demonstrating reliable and consistent performance. The results suggest that this model is suitable for further deployment or comparison with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0afvixsvErB",
    "outputId": "0ff1c4b3-a433-48b2-8c59-103d90bdce72"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_cv_model = xgb.XGBRegressor(\n",
    "    booster='gbtree',\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Perform 10-fold cross-validation for RMSE\n",
    "rmse_scores_xgb = cross_val_score(\n",
    "    xgb_cv_model, X_train_processed, y_train,\n",
    "    cv=10, scoring='neg_mean_squared_error'\n",
    ")\n",
    "mean_rmse_xgb = np.sqrt(-rmse_scores_xgb).mean()\n",
    "\n",
    "# Perform 10-fold cross-validation for MAE\n",
    "mae_scores_xgb = cross_val_score(\n",
    "    xgb_cv_model, X_train_processed, y_train,\n",
    "    cv=10, scoring='neg_mean_absolute_error'\n",
    ")\n",
    "mean_mae_xgb = -mae_scores_xgb.mean()\n",
    "\n",
    "print(f\"Mean RMSE (XGBoost): {mean_rmse_xgb}\")\n",
    "print(f\"Mean MAE (XGBoost): {mean_mae_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "uCXSG-OIBVJW",
    "outputId": "bd289ec7-de98-4eea-ad6e-614a5c5f6179"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# RMSE and MAE fold scores\n",
    "rmse_fold_scores = np.sqrt(-rmse_scores_xgb)\n",
    "mae_fold_scores = -mae_scores_xgb\n",
    "\n",
    "# Plot RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 11), rmse_fold_scores, marker='o', label='RMSE')\n",
    "plt.plot(range(1, 11), mae_fold_scores, marker='x', label='MAE')\n",
    "plt.xlabel('Cross-Validation Fold')\n",
    "plt.ylabel('Error Value')\n",
    "plt.title('XGBoost Cross-Validation RMSE and MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgqlijQdvcP_"
   },
   "source": [
    "# XGBOOST FINAL MODEL EVALUATION ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz1fXWEavb3X",
    "outputId": "5958ca65-bfcb-44c6-e05b-316cd4873fb6"
   },
   "outputs": [],
   "source": [
    "# XGBoost Predictions\n",
    "# Reset X_train_processed and X_test_processed using the original train_test_split\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "# Recreate the DMatrix for training and test set with the correct data\n",
    "dtrain = xgb.DMatrix(X_train_processed, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_processed, label=y_test)\n",
    "\n",
    "xgb_model_final = xgb.train(\n",
    "    params=xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=100\n",
    ")\n",
    "xgb_predictions = xgb_model_final.predict(dtest)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_rmse_test = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "xgb_mae_test = mean_absolute_error(y_test, xgb_predictions)\n",
    "print(\"XGBoost Test RMSE:\", xgb_rmse_test)\n",
    "print(\"XGBoost Test MAE:\", xgb_mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxKGTfc49G8b"
   },
   "source": [
    "#IMPLEMENT LIGHTGBM (DISTRIBUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "I4d75F249JoH",
    "outputId": "a69434da-636a-44c2-e3d2-20d7e0f19371"
   },
   "outputs": [],
   "source": [
    "# Set LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': ['rmse', 'l2'],\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 20,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Track training time\n",
    "start_train_time = time.time()\n",
    "\n",
    "# Train LightGBM model\n",
    "train_data = lgb.Dataset(X_train_processed, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_processed, label=y_test, reference=train_data)\n",
    "evals_result_lgb = {}\n",
    "model = lgb.train(lgb_params,\n",
    "                  train_data,\n",
    "                  num_boost_round=100,\n",
    "                  valid_sets=[train_data, test_data],  # valid_sets argument\n",
    "\n",
    "                  valid_names=['train', 'eval'],         # This is necessary for the key 'eval' to be created in evals_result_lgb\n",
    "                  callbacks=[lgb.record_evaluation(evals_result_lgb)]\n",
    "                                )\n",
    "\n",
    "end_train_time = time.time()\n",
    "training_time = end_train_time - start_train_time\n",
    "\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Track running (inference) time\n",
    "start_run_time = time.time()\n",
    "y_pred = model.predict(X_test_processed[:len(y_test)], num_iteration=model.best_iteration) # Slice X_test_processed to match y_test length\n",
    "end_run_time = time.time()\n",
    "running_time = end_run_time - start_run_time\n",
    "\n",
    "print(f\"Running (Prediction) Time: {running_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate the model performance\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "\n",
    "# Extract RMSE and MAE for each iteration\n",
    "validation_rmse_lgb = evals_result_lgb['eval']['rmse']\n",
    "validation_mae_lgb = evals_result_lgb['eval']['l2']\n",
    "\n",
    "\n",
    "# Plot Validation RMSE and MAE over iterations for LightGBM\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(validation_rmse_lgb, label='Validation RMSE', color='blue')\n",
    "plt.plot(validation_mae_lgb, label='Validation MAE', color='green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('LightGBM Training Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FHH6LoD-EVu"
   },
   "source": [
    "TRAINING LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "qSmZMR1U-HQL",
    "outputId": "63131199-8da7-4256-e37d-8e1d30998788"
   },
   "outputs": [],
   "source": [
    "# Extract Metrics\n",
    "train_loss = evals_result_lgb['train']['rmse']\n",
    "valid_loss = evals_result_lgb['eval']['rmse']\n",
    "iterations = np.arange(len(train_loss)) + 1\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, train_loss, label='Training Loss (RMSE)', color='blue')\n",
    "plt.plot(iterations, valid_loss, label='Validation Loss (RMSE)', color='orange')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Distributed LightGBM: Training and Validation Loss vs Iterations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2L5tdPD_jQD"
   },
   "source": [
    "# Lightgbm RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkSmVLDM_lfi"
   },
   "outputs": [],
   "source": [
    "# Use the same parameter grid\n",
    "param_dist_lgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 50, 70],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 1],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'min_child_samples': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for LightGBM\n",
    "random_search_lgb = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=50,  # Limit to 50 random combinations\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search_lgb.fit(X_train_processed, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for LightGBM:\", random_search_lgb.best_params_)\n",
    "print(\"Best RMSE (negative MSE):\", (-random_search_lgb.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmS4w9eb_5GG"
   },
   "source": [
    "#Lightgbm Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEVg9iET_3tg",
    "outputId": "6e7bdc37-fa04-4ae6-b6a5-cdd3d777c090"
   },
   "outputs": [],
   "source": [
    "# Initialize LightGBM regressor\n",
    "lgb_cv_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=20,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "X_train_processed = X_train_processed[:len(y_train)]  # Adjust X_train_processed to match y_train's length\n",
    "# Perform 10-fold cross-validation for RMSE\n",
    "rmse_scores_lgb = cross_val_score(\n",
    "    lgb_cv_model, X_train_processed, y_train,\n",
    "    cv=10, scoring='neg_mean_squared_error'\n",
    ")\n",
    "mean_rmse_lgb = np.sqrt(-rmse_scores_lgb).mean()\n",
    "\n",
    "# Perform 10-fold cross-validation for MAE\n",
    "mae_scores_lgb = cross_val_score(\n",
    "    lgb_cv_model, X_train_processed, y_train,\n",
    "    cv=10, scoring='neg_mean_absolute_error'\n",
    ")\n",
    "mean_mae_lgb = -mae_scores_lgb.mean()\n",
    "\n",
    "print(f\"Mean RMSE (LightGBM): {mean_rmse_lgb}\")\n",
    "print(f\"Mean MAE (LightGBM): {mean_mae_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "-HgRdEDnHraI",
    "outputId": "a5b0938a-e7de-4b1c-9324-8714d132561d"
   },
   "outputs": [],
   "source": [
    "# Plot RMSE and MAE for each fold\n",
    "folds = range(1, 11)  # Number of folds\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Assuming rmse_scores_lgb and mae_scores_lgb are from your cross-validation\n",
    "rmse_values = np.sqrt(-rmse_scores_lgb) # Calculate RMSE values\n",
    "mae_values = -mae_scores_lgb  # Calculate MAE values\n",
    "\n",
    "plt.plot(folds, rmse_values, marker='o', label='RMSE')\n",
    "plt.plot(folds, mae_values, marker='x', label='MAE')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('LightGBM Cross-Validation RMSE and MAE')\n",
    "plt.xlabel('Cross-Validation Fold')\n",
    "plt.ylabel('Error Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q8D_jX-AL4C"
   },
   "source": [
    "FINAL LIGHTGBM MODEL EVALUATION ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qGtd3bHAO2S",
    "outputId": "c1793b41-2121-49b2-c14c-9b1a34547536"
   },
   "outputs": [],
   "source": [
    "# LightGBM Predictions\n",
    "lgb_predictions = model.predict(X_test_processed, num_iteration=model.best_iteration)  # Use 'model' instead of 'lgb_model'\n",
    "\n",
    "# Evaluate LightGBM\n",
    "lgb_rmse_test = np.sqrt(mean_squared_error(y_test, lgb_predictions))\n",
    "lgb_mae_test = mean_absolute_error(y_test, lgb_predictions)\n",
    "print(\"LightGBM Test RMSE:\", lgb_rmse_test)\n",
    "print(\"LightGBM Test MAE:\", lgb_mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIUur860BTtp"
   },
   "source": [
    "#IMPLEMENT LIGHTGBM (NON-DISTRIBUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOgsg-ATBaJn",
    "outputId": "b98fb14a-0ba2-4cae-caa2-1f8bc3ec3f8b"
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "#X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 70% train, 30% temp\n",
    "#X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% valid, 15% test\n",
    "\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)\n",
    "# Prepare LightGBM datasets\n",
    "X_valid_processed = pipeline.transform(X_valid)\n",
    "valid_data = lgb.Dataset(X_valid_processed, label=y_valid)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',  # Metric for LightGBM\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.02805795401088166,\n",
    "    'num_leaves': 25,\n",
    "    'max_depth': 3,\n",
    "    'verbose': -1,\n",
    "    'colsample_bytree': 0.8607324052224274,\n",
    "    'min_child_samples': 18,\n",
    "    'n_estimators': 223,\n",
    "    'subsample': 0.9087438420372645,\n",
    "    'feature_pre_filter': False\n",
    "}\n",
    "\n",
    "# Create train_data after defining params with feature_pre_filter\n",
    "train_data = lgb.Dataset(X_train_processed, label=y_train, params=params) # Pass params to the Dataset constructor\n",
    "valid_data = lgb.Dataset(X_valid_processed, label=y_valid, params=params)  # Pass params to the Dataset constructor as well\n",
    "\n",
    "# Initialize an empty dictionary to store evaluation results\n",
    "evals_result = {}\n",
    "\n",
    "# Train the model\n",
    "print(\"Training LightGBM in non-distributed mode...\")\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "\n",
    "        ]\n",
    ")\n",
    "\n",
    "end_train_time = time.time()\n",
    "training_time = end_train_time - start_train_time\n",
    "\n",
    "# Record the inference time\n",
    "print(\"Running inference on test data...\")\n",
    "start_run_time = time.time()\n",
    "y_pred = model.predict(X_valid_processed, num_iteration=model.best_iteration)\n",
    "end_run_time = time.time()\n",
    "\n",
    "running_time = end_run_time - start_run_time\n",
    "\n",
    "# Evaluate performance\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n--- LightGBM Model Evaluation (Non-Distributed) ---\")\n",
    "print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "print(f\"Running (Inference) Time: {running_time:.4f} seconds\")\n",
    "print(f\"LightGBM (Non-Distributed)  RMSE: {rmse:.4f}\")\n",
    "print(f\"LightGBM (Non-Distributed) MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "gOptGhcfCgaw",
    "outputId": "602f3b20-1c55-4fff-d05a-5c53dee7eda9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# RMSE (from LightGBM metrics)\n",
    "train_rmse = evals_result['training']['rmse']  # Access using 'valid_0'\n",
    "valid_rmse = evals_result['valid_1']['rmse']  # Access using 'valid_0'\n",
    "\n",
    "# Plot RMSE\n",
    "plt.plot(train_rmse, label='Train RMSE', color='blue')\n",
    "plt.plot(valid_rmse, label='Valid RMSE', color='red')\n",
    "\n",
    "# Add MAE as a separate point for visualization\n",
    "plt.axhline(y=mae, color='green', linestyle='--', label=f'Final MAE: {mae:.4f}')\n",
    "\n",
    "# Labels and legend\n",
    "plt.title(\"RMSE and MAE during LightGBM Training\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pc68svhCtaf"
   },
   "source": [
    "# Plot Training and validation Loss for lightgbm (NON-DISTRIBUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "fN9fTDdvCuHK",
    "outputId": "1b33b208-154b-4641-d2af-0b7bcaaf2891"
   },
   "outputs": [],
   "source": [
    "# Extract the metrics\n",
    "train_loss = evals_result['training']['rmse']  # Training RMSE at each iteration\n",
    "valid_loss = evals_result['valid_1']['rmse']  # Validation RMSE at each iteration\n",
    "iterations = np.arange(len(train_loss)) + 1  # Iteration numbers (1 to num_boost_round)\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, train_loss, label='Training Loss (RMSE)', color='blue')\n",
    "plt.plot(iterations, valid_loss, label='Validation Loss (RMSE)', color='orange')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training and Validation Loss vs Iterations')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNh62-JlELOd"
   },
   "source": [
    "TUNING LIGHTGBM (NON-DISTRIBUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyFPo4CiEQbm",
    "outputId": "ec8c6c9a-1dbb-41bf-bfd3-639c0daf712a"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', random_state=42)\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'num_leaves': randint(20, 70),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'min_child_samples': randint(10, 30),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3)\n",
    "}\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],  # Calculate both RMSE and MAE\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    refit='neg_mean_squared_error'  # Specify which metric to use for refitting\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "X_train_processed_original = pipeline.fit_transform(X)\n",
    "print(\"Starting Randomized Search for LightGBM...\")\n",
    "\n",
    "random_search.fit(X_train_processed_original, y)  # Use original y which is target column\n",
    "# Best parameters and RMSE\n",
    "best_params = random_search.best_params_\n",
    "best_rmse = np.sqrt(-random_search.best_score_)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_rmse)\n",
    "\n",
    "\n",
    "# Extract corresponding MAE for the best RMSE\n",
    "results = random_search.cv_results_\n",
    "best_index = random_search.best_index_\n",
    "best_mae = -results['mean_test_neg_mean_absolute_error'][best_index]  # Access MAE scores\n",
    "print(\"Corresponding MAE:\", best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDVD2alMEeyG"
   },
   "source": [
    "LIGHTGBM(NON-DISTRIBUTED) CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jM1cNUcERM6",
    "outputId": "580ca724-c888-4ffe-d211-03d6b16e4c9a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Prepare LightGBM Dataset\n",
    "train_data = lgb.Dataset(X_train_processed, label=y_train)\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',  # Metric for LightGBM\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.02805795401088166,\n",
    "    'num_leaves': 25,\n",
    "    'max_depth': 3,\n",
    "    'verbose': -1,\n",
    "    'colsample_bytree': 0.8607324052224274,\n",
    "    'min_child_samples': 18,\n",
    "    'n_estimators': 223,\n",
    "    'subsample': 0.9087438420372645\n",
    "}\n",
    "\n",
    "# KFold Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize metrics for cross-validation\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "training_times = []\n",
    "\n",
    "# Cross-Validation Loop\n",
    "print(\"Performing Cross-Validation...\")\n",
    "fold = 1\n",
    "for train_index, valid_index in kf.split(X_train_processed):\n",
    "    print(f\"\\nFold {fold}...\")\n",
    "    X_train_fold, X_valid_fold = X_train_processed[train_index], X_train_processed[valid_index]\n",
    "\n",
    "    # Use .iloc to access data based on integer position\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    # Create LightGBM Datasets\n",
    "    train_fold_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    valid_fold_data = lgb.Dataset(X_valid_fold, label=y_valid_fold)\n",
    "\n",
    "    # Measure training time for each fold\n",
    "    start_train_time = time.time()\n",
    "    model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_fold_data,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[valid_fold_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)],\n",
    "\n",
    ")\n",
    "    end_train_time = time.time()\n",
    "    training_time = end_train_time - start_train_time\n",
    "\n",
    "    # Store training time\n",
    "    training_times.append(training_time)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid_fold, num_iteration=model.best_iteration)\n",
    "\n",
    "    # Evaluate RMSE and MAE\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid_fold, y_pred))\n",
    "    mae = mean_absolute_error(y_valid_fold, y_pred)\n",
    "\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "    print(f\"Fold {fold} RMSE: {rmse:.4f}, MAE: {mae:.4f}, Training Time: {training_time:.4f} seconds\")\n",
    "    fold += 1\n",
    "\n",
    "# Cross-Validation Results\n",
    "print(\"\\n--- Cross-Validation Results ---\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ND9mwQY5KAKZ",
    "outputId": "8b667c3f-17ef-4002-c0fb-1d4cdbd49e4f"
   },
   "outputs": [],
   "source": [
    "# Number of Cross-Validation Folds\n",
    "folds = range(1, 6)  # Assuming 5-fold CV based on the previous cell's KFold\n",
    "\n",
    "# Plot RMSE and MAE (Using rmse_list and mae_list from previous cell)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Assuming rmse_list and mae_list are from the previous cell (cell 56)\n",
    "plt.plot(folds, rmse_list, marker='o', label='RMSE')\n",
    "plt.plot(folds, mae_list, marker='x', label='MAE')\n",
    "\n",
    "# Customize Plot\n",
    "plt.title('LightGBM Non-Distributed Cross-Validation RMSE and MAE')\n",
    "plt.xlabel('Cross-Validation Fold')\n",
    "plt.ylabel('Error Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI-TSMTpE21U"
   },
   "source": [
    "#FINAL EVALUATION OF LIGHTGBM(NON-DISTRIBUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-tyDnK7E2Qf",
    "outputId": "246a7794-4b69-41ba-c9aa-207af7ebc938"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set using the best iteration\n",
    "y_test_pred = model.predict(X_test_processed, num_iteration=model.best_iteration) # Use the correct X_test_processed\n",
    "\n",
    "# Calculate RMSE and MAE for the test set\n",
    "rmse_lgb_non = np.sqrt(mean_squared_error(y_test, y_test_pred)) #  y_test should remain the same\n",
    "mae_lgb_non = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print final results\n",
    "print(\"Final Model Evaluation on Test Set:\")\n",
    "print(f\"LightGBM (Non-Distributed) TestTest RMSE: {rmse_lgb_non:.4f}\")\n",
    "print(f\"LightGBM (Non-Distributed)Test MAE: { mae_lgb_non:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz167fDyFFRA"
   },
   "source": [
    "#3 MODELS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "T3wzUWKkFJim",
    "outputId": "4a51cbbd-53ed-415d-9541-33c4de0ce41c"
   },
   "outputs": [],
   "source": [
    "models = ['XGBoost', 'LightGBM Non-Distributed', 'LightGBM Distributed']\n",
    "rmse_values = [rmse_xgb, rmse_lgb_non, lgb_rmse_test]\n",
    "mae_values = [mae_xgb, mae_lgb_non, lgb_mae_test]\n",
    "\n",
    "x = range(len(models))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, rmse_values, width=0.4, label='RMSE', align='center')\n",
    "plt.bar(x, mae_values, width=0.4, label='MAE', align='edge')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Error (RMSE / MAE)')\n",
    "plt.title('Model Comparison: RMSE and MAE')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}